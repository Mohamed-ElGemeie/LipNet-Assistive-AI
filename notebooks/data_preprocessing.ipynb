{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "from typing import Tuple, Union\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import random\n",
    "from celluloid import Camera \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import display, Image\n",
    "from tensorflow.keras.models import Sequential ,model_from_json\n",
    "from tensorflow.keras.layers import Conv3D,GRU, Dense, Dropout, Bidirectional, MaxPool3D, Activation, TimeDistributed, Flatten, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import keras\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels\n",
    "MARGIN = 0\n",
    "ROW_SIZE = 0\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "\n",
    "# Input model Image size\n",
    "IMAGE_SIZE = (100, 200)\n",
    "\n",
    "batch_size = 1\n",
    "mp_face_mesh =  mp.solutions.face_mesh.FaceMesh(max_num_faces=1,static_image_mode=True, min_detection_confidence=0.2)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_arab(alignments):\n",
    "    sub_arrays = []\n",
    "    current_sub_array = []\n",
    "    for element in num_to_char(alignments).numpy():\n",
    "        if element.decode(\"utf-8\") == \"\":\n",
    "            if current_sub_array:  # Add a non-empty sub-array\n",
    "                sub_arrays.append(current_sub_array)\n",
    "            current_sub_array = []  # Start a new sub-array\n",
    "        else:\n",
    "            current_sub_array.append(element.decode(\"utf-8\"))\n",
    "\n",
    "    if current_sub_array:  # Add the last sub-array if it's not empty\n",
    "        sub_arrays.append(current_sub_array)\n",
    "\n",
    "    for i in sub_arrays:\n",
    "        print(''.join(i),end=\" \")\n",
    "def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "    \"\"\"Converts normalized values to pixel coordinates.\"\"\"\n",
    "    x_px = min(max(int(normalized_x * image_width), 0), image_width)\n",
    "    y_px = min(max(int(normalized_y * image_height), 0), image_height)\n",
    "    return x_px, y_px\n",
    "\n",
    "def contrast_based_histogram_equalization_rgb(image):\n",
    "    # # Convert the image to uint8 if not already\n",
    "    # if image.dtype != np.uint8:\n",
    "    #     image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Split channels\n",
    "    channels = cv2.split(image)\n",
    "\n",
    "    # Apply histogram equalization to each channel\n",
    "    equalized_channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "\n",
    "    # Merge channels\n",
    "    equalized_image = cv2.merge(equalized_channels)\n",
    "\n",
    "    return equalized_image\n",
    "\n",
    "def clahe_equalization_rgb(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    # Split LAB image into L, A, B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
    "    clahe_l_channel = clahe.apply(l_channel)\n",
    "\n",
    "    # Merge the enhanced L channel with the original A and B channels\n",
    "    clahe_lab_image = cv2.merge((clahe_l_channel, a_channel, b_channel))\n",
    "\n",
    "    # Convert the LAB image back to RGB\n",
    "    clahe_rgb_image = cv2.cvtColor(clahe_lab_image, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return clahe_rgb_image\n",
    "\n",
    "def scale_image_0_1(image):\n",
    "\n",
    "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "def scale_image__1_1(image):\n",
    "\n",
    "    normalized_image = 2 * (image - np.min(image, axis=(0, 1))) / (np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))) - 1\n",
    "    normalized_image = np.clip(normalized_image, -1, 1)\n",
    "    \n",
    "    return normalized_image\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def inner_angle(point1, point2, point3):\n",
    "    a = np.array(point1)\n",
    "    b = np.array(point2)\n",
    "    c = np.array(point3)\n",
    "\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def display_gif(video):\n",
    "    merged_array = np.concatenate((video.numpy(), video.numpy(), video.numpy()), axis=-1)\n",
    "    print(merged_array.shape)\n",
    "    fig, ax = plt.subplots() # make it bigger\n",
    "    camera = Camera(fig)# the camera gets our figure\n",
    "    for img in os.listdir(\"NST/epochs\"):\n",
    "        img_obj = plt.imread(os.path.join(\"NST/epochs\"), img) # reading\n",
    "        ax.imshow(img_obj) # plotting\n",
    "        camera.snap()\n",
    "    animation = camera.animate()\n",
    "    HTML(animation.to_html5_video())\n",
    "    clip = ImageSequenceClip(list(scale_image_0_1(merged_array)*255), fps=25)\n",
    "    clip.write_gif('test.gif', fps=25)\n",
    "    return Image('test.gif')\n",
    "\n",
    "def use_camera():\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "    average_angle = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Broken image\")\n",
    "            continue\n",
    "\n",
    "        # Convert to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get face mesh landmarks\n",
    "        results = mp_face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                image_rows, image_cols, _ = frame.shape\n",
    "                normalized_point = normalized_to_pixel_coordinates(1,1, image_cols, image_rows)\n",
    "\n",
    "                left_lip = face_landmarks.landmark[0]\n",
    "                right_lip = face_landmarks.landmark[17]\n",
    "                left = face_landmarks.landmark[192]\n",
    "                bottom= face_landmarks.landmark[199]\n",
    "                top = face_landmarks.landmark[2]\n",
    "                right = face_landmarks.landmark[416]\n",
    "\n",
    "                bottom_px = normalized_to_pixel_coordinates(bottom.x, bottom.y, image_cols, image_rows)\n",
    "                left_px = normalized_to_pixel_coordinates(left.x, left.y, image_cols, image_rows)\n",
    "                top_px = normalized_to_pixel_coordinates(top.x, top.y, image_cols, image_rows)\n",
    "                right_px = normalized_to_pixel_coordinates(right.x, right.y, image_cols, image_rows)\n",
    "                left_lip = normalized_to_pixel_coordinates(left_lip.x, left_lip.y, image_cols, image_rows)\n",
    "                right_lip = normalized_to_pixel_coordinates(right_lip.x, right_lip.y, image_cols, image_rows)\n",
    "\n",
    "\n",
    "                midpoint = [(left_lip[0]+right_lip[0])//2,(left_lip[1]+right_lip[1])//2]\n",
    "\n",
    "                # Calculate the differences in x and y coordinates\n",
    "                dx = right_lip[0] - midpoint[0]\n",
    "                dy = right_lip[1] - midpoint[1]\n",
    "                \n",
    "                # # Calculate the angle using arctan(dy/dx)\n",
    "                angle_radians = math.atan2(dy, dx)\n",
    "                \n",
    "                # # Convert radians to degrees\n",
    "                angle_degrees = math.degrees(angle_radians) - 90\n",
    "\n",
    "                if len(average_angle) <6:\n",
    "                    average_angle.append(angle_degrees)\n",
    "                else:\n",
    "                    average_angle.pop(0)\n",
    "                    average_angle.append(angle_degrees)\n",
    "                    \n",
    "                if sum(average_angle) == 0:\n",
    "                    angle_degrees = 0\n",
    "                else:\n",
    "                    angle_degrees = sum(average_angle) / len(average_angle)\n",
    "\n",
    "                # # Rotate the image\n",
    "                rotation_matrix = cv2.getRotationMatrix2D(midpoint, angle_degrees, 1.0)\n",
    "                frame = cv2.warpAffine(frame, rotation_matrix, (normalized_point))\n",
    "\n",
    "                # Convert rotated points back to list of tuples\n",
    "                bottom_px , left_px , top_px , right_px = [(int(point[0][0]), int(point[0][1])) for point in cv2.transform(np.array([bottom_px , left_px , top_px , right_px]).reshape(-1, 1, 2).astype(np.float64), rotation_matrix)]\n",
    "\n",
    "                if not (frame.shape[0] >0 and frame.shape[1] >0 and frame.shape[2] ==3):\n",
    "                    continue\n",
    "\n",
    "                frame = frame[\n",
    "                        top_px[1] : bottom_px[1],\n",
    "                        left_px[0] : right_px[0],\n",
    "                        :,\n",
    "                    ]\n",
    "                \n",
    "                if not (frame.shape[0] >0 and frame.shape[1] >0 and frame.shape[2] ==3):\n",
    "                    continue\n",
    "\n",
    "                frame = cv2.resize(\n",
    "                        frame, (IMAGE_SIZE[1],IMAGE_SIZE[0]), interpolation=cv2.INTER_LANCZOS4\n",
    "                    )\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "                # frame = cv2.equalizeHist(frame)\n",
    "                frame = clahe.apply(frame)\n",
    "                frame = gaussian_filter(frame, sigma=0.2)\n",
    "\n",
    "                mean = np.mean(frame, axis=(0, 1))  \n",
    "                std = np.std(frame, axis=(0, 1))    \n",
    "                frame = (frame - mean) / std\n",
    "                cv2.imshow(\"frame\", scale_image_0_1 (frame))\n",
    "                break\n",
    "\n",
    "        # Display the frame\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# use_camera()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path: str) -> List[float]:\n",
    "    # opens the video's path as a camera object\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # frames of the video\n",
    "    frames = np.empty((MAX_FRAMES, IMAGE_SIZE[0], IMAGE_SIZE[1], 1))\n",
    "    average_angle = []\n",
    "    idx = 0\n",
    "\n",
    "    # loop over all frames in the video\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        # if _ == 0:\n",
    "        #     continue\n",
    "        try:\n",
    "            ret, frame = cap.read()\n",
    "            image_rows, image_cols, _ = frame.shape\n",
    "            # convert to rgb\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # get the keypoints (x,y)s of each point of a face in the frame\n",
    "            face_mesh_result = mp_face_mesh.process(frame)\n",
    "\n",
    "            # loop over each face landmark ~ (nose (x,y) lips (x,y) and so one and a bounding box)\n",
    "            if face_mesh_result.multi_face_landmarks:\n",
    "\n",
    "                for face_landmarks in face_mesh_result.multi_face_landmarks:\n",
    "\n",
    "                    normalized_point = normalized_to_pixel_coordinates(1,1, image_cols, image_rows)\n",
    "\n",
    "                    left_lip = face_landmarks.landmark[0]\n",
    "                    right_lip = face_landmarks.landmark[17]\n",
    "                    left = face_landmarks.landmark[192]\n",
    "                    bottom= face_landmarks.landmark[199]\n",
    "                    top = face_landmarks.landmark[2]\n",
    "                    right = face_landmarks.landmark[416]\n",
    "\n",
    "                    bottom_px = normalized_to_pixel_coordinates(bottom.x, bottom.y, image_cols, image_rows)\n",
    "                    left_px = normalized_to_pixel_coordinates(left.x, left.y, image_cols, image_rows)\n",
    "                    top_px = normalized_to_pixel_coordinates(top.x, top.y, image_cols, image_rows)\n",
    "                    right_px = normalized_to_pixel_coordinates(right.x, right.y, image_cols, image_rows)\n",
    "                    left_lip = normalized_to_pixel_coordinates(left_lip.x, left_lip.y, image_cols, image_rows)\n",
    "                    right_lip = normalized_to_pixel_coordinates(right_lip.x, right_lip.y, image_cols, image_rows)\n",
    "\n",
    "\n",
    "                    midpoint = [(left_lip[0]+right_lip[0])//2,(left_lip[1]+right_lip[1])//2]\n",
    "\n",
    "                    # Calculate the differences in x and y coordinates\n",
    "                    dx = right_lip[0] - midpoint[0]\n",
    "                    dy = right_lip[1] - midpoint[1]\n",
    "                    \n",
    "                    # # Calculate the angle using arctan(dy/dx)\n",
    "                    angle_radians = math.atan2(dy, dx)\n",
    "                    \n",
    "                    # # Convert radians to degrees\n",
    "                    angle_degrees = math.degrees(angle_radians) - 90\n",
    "\n",
    "                    if len(average_angle) <6:\n",
    "                        average_angle.append(angle_degrees)\n",
    "                    else:\n",
    "                        average_angle.pop(0)\n",
    "                        average_angle.append(angle_degrees)\n",
    "                        \n",
    "                    if sum(average_angle) == 0:\n",
    "                        angle_degrees = 0\n",
    "                    else:\n",
    "                        angle_degrees = sum(average_angle) / len(average_angle)\n",
    "\n",
    "                    # Rotate the image\n",
    "                    rotation_matrix = cv2.getRotationMatrix2D(midpoint, angle_degrees, 1.0)\n",
    "                    frame = cv2.warpAffine(frame, rotation_matrix, (normalized_point))\n",
    "\n",
    "                    # Convert rotated points back to list of tuples\n",
    "                    bottom_px , left_px , top_px , right_px = [(int(point[0][0]), int(point[0][1])) for point in cv2.transform(np.array([bottom_px , left_px , top_px , right_px]).reshape(-1, 1, 2).astype(np.float64), rotation_matrix)]\n",
    "\n",
    "                    if not (frame.shape[0] >0 and frame.shape[1] >0 and frame.shape[2] ==3):\n",
    "                        continue\n",
    "\n",
    "                    frame = frame[\n",
    "                            top_px[1] : bottom_px[1],\n",
    "                            left_px[0] : right_px[0],\n",
    "                            :,\n",
    "                        ]\n",
    "                    \n",
    "                    if not (frame.shape[0] >0 and frame.shape[1] >0 and frame.shape[2] ==3):\n",
    "                        continue\n",
    "\n",
    "                    frame = cv2.resize(\n",
    "                            frame, (IMAGE_SIZE[1],IMAGE_SIZE[0]), interpolation=cv2.INTER_LANCZOS4\n",
    "                        )\n",
    "\n",
    "                    # frame = clahe_equalization_rgb(frame)\n",
    "\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "                    frame = clahe.apply(frame)\n",
    "                    frame = gaussian_filter(frame, sigma=0.2)\n",
    "\n",
    "                        \n",
    "                    mean = np.mean(frame)  \n",
    "                    std = np.std(frame)    \n",
    "                    frame = (frame - mean) / std\n",
    "                    \n",
    "                    frames[idx] = frame.reshape((*IMAGE_SIZE,1))\n",
    "\n",
    "                    idx += 1\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "                # Handle the case where the landmarks are not found\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    cap.release()\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # normalize on the scale of the video\n",
    "    # mean = tf.math.reduce_mean(frames)\n",
    "    # std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    # frames = tf.cast((frames - mean), tf.float32) / std\n",
    "    frames = tf.cast(frames, tf.float32)\n",
    "    if idx < MAX_FRAMES:\n",
    "        for i in range(idx, MAX_FRAMES):\n",
    "            frames = tf.tensor_scatter_nd_update(frames, [[i]], tf.zeros((1, IMAGE_SIZE[0], IMAGE_SIZE[1], 1), dtype=tf.float32))\n",
    "\n",
    "    # frames = tf.cast(tf.convert_to_tensor(frames),tf.float32)\n",
    "    \n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gif(load_video(FILTERED_VIDEOS + fr\"/{VIDEO_DIR[0]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num([\"\",\"ا\", \"ن\", \"ا\", \" \", \"ا\", \"ن\", \"ا\", \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_arab([1, 25, 1,0, 1, 25, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str): \n",
    "\n",
    "    path = bytes.decode(path.numpy())\n",
    "    \n",
    "    file_name = path.replace(\"\\\\\",\"/\").split('/')[-1].split('.')[0]\n",
    "    video_path = FILTERED_VIDEOS + fr'/{file_name}.mp4'\n",
    "    alignment_path = FILTERED_ALIGNMENTS + fr'/{file_name}.align'\n",
    "\n",
    "    frames = load_video(video_path) \n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gif(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_arab(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_vtt_to_srt(vtt_file_path, srt_file_path):\n",
    "    with open(vtt_file_path, 'r', encoding='utf-8') as vtt_file:\n",
    "        lines = vtt_file.readlines()\n",
    "\n",
    "    srt_lines = []\n",
    "    counter = 1\n",
    "\n",
    "    for line in lines:\n",
    "        # Skip WebVTT-specific lines\n",
    "        if line.startswith(\"WEBVTT\") or line.startswith(\"NOTE\"):\n",
    "            continue\n",
    "        \n",
    "        # Replace VTT timestamp comma with SRT timestamp period\n",
    "        if '-->' in line:\n",
    "            line = line.replace('.', ',')  # Replace the first period with a comma for SRT format\n",
    "\n",
    "        # Add counter at the beginning of each subtitle block\n",
    "        if '-->' in line:\n",
    "            srt_lines.append(str(counter))\n",
    "            counter += 1\n",
    "        \n",
    "        srt_lines.append(line.strip())\n",
    "\n",
    "    with open(srt_file_path, 'w', encoding='utf-8') as srt_file:\n",
    "        srt_file.write('\\n'.join(srt_lines))\n",
    "        srt_file.write('\\n')\n",
    "\n",
    "# Usage\n",
    "convert_vtt_to_srt(r'D:/Code-Projects/University/Fall2023/Grad/LipNet-Assistive-AI/notebooks/sub.srt.ar.vtt', 'output.srt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\n",
      "[youtube] bpu2hbpQpCY: Downloading webpage\n",
      "[youtube] bpu2hbpQpCY: Downloading ios player API JSON\n",
      "[youtube] bpu2hbpQpCY: Downloading player 8eff86d5\n",
      "[youtube] bpu2hbpQpCY: Downloading m3u8 information\n",
      "[info] bpu2hbpQpCY: Downloading subtitles: ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No subtitle format found matching \"srt\" for language ar, using vtt. Use --list-subs for a list of available subtitles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] bpu2hbpQpCY: Downloading 1 format(s): 303+251\n",
      "[info] Writing video subtitles to: sub.srt.ar.vtt\n",
      "[download] Destination: sub.srt.ar.vtt\n",
      "[download] 100% of   20.20KiB in 00:00:00 at 120.94KiB/s\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\"\n",
    "\n",
    "ydl_opts = {\n",
    "  'subtitleslangs': ['ar'],\n",
    "  'writeautomaticsub': True,\n",
    "  'subtitlesformat': 'srt',\n",
    "  'skip_download': True,\n",
    "  'outtmpl': 'sub.srt' \n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "  ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\n",
      "[youtube] bpu2hbpQpCY: Downloading webpage\n",
      "[youtube] bpu2hbpQpCY: Downloading ios player API JSON\n",
      "[youtube] bpu2hbpQpCY: Downloading m3u8 information\n",
      "[info] Available automatic captions for bpu2hbpQpCY:\n",
      "Language Name                  Formats\n",
      "af       Afrikaans             vtt, ttml, srv3, srv2, srv1, json3\n",
      "ak       Akan                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "sq       Albanian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "am       Amharic               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ar-orig  Arabic (Original)     vtt, ttml, srv3, srv2, srv1, json3\n",
      "ar       Arabic                vtt, ttml, srv3, srv2, srv1, json3\n",
      "hy       Armenian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "as       Assamese              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ay       Aymara                vtt, ttml, srv3, srv2, srv1, json3\n",
      "az       Azerbaijani           vtt, ttml, srv3, srv2, srv1, json3\n",
      "bn       Bangla                vtt, ttml, srv3, srv2, srv1, json3\n",
      "eu       Basque                vtt, ttml, srv3, srv2, srv1, json3\n",
      "be       Belarusian            vtt, ttml, srv3, srv2, srv1, json3\n",
      "bho      Bhojpuri              vtt, ttml, srv3, srv2, srv1, json3\n",
      "bs       Bosnian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "bg       Bulgarian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "my       Burmese               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ca       Catalan               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ceb      Cebuano               vtt, ttml, srv3, srv2, srv1, json3\n",
      "zh-Hans  Chinese (Simplified)  vtt, ttml, srv3, srv2, srv1, json3\n",
      "zh-Hant  Chinese (Traditional) vtt, ttml, srv3, srv2, srv1, json3\n",
      "co       Corsican              vtt, ttml, srv3, srv2, srv1, json3\n",
      "hr       Croatian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "cs       Czech                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "da       Danish                vtt, ttml, srv3, srv2, srv1, json3\n",
      "dv       Divehi                vtt, ttml, srv3, srv2, srv1, json3\n",
      "nl       Dutch                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "en       English               vtt, ttml, srv3, srv2, srv1, json3\n",
      "eo       Esperanto             vtt, ttml, srv3, srv2, srv1, json3\n",
      "et       Estonian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ee       Ewe                   vtt, ttml, srv3, srv2, srv1, json3\n",
      "fil      Filipino              vtt, ttml, srv3, srv2, srv1, json3\n",
      "fi       Finnish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "fr       French                vtt, ttml, srv3, srv2, srv1, json3\n",
      "gl       Galician              vtt, ttml, srv3, srv2, srv1, json3\n",
      "lg       Ganda                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "ka       Georgian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "de       German                vtt, ttml, srv3, srv2, srv1, json3\n",
      "el       Greek                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "gn       Guarani               vtt, ttml, srv3, srv2, srv1, json3\n",
      "gu       Gujarati              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ht       Haitian Creole        vtt, ttml, srv3, srv2, srv1, json3\n",
      "ha       Hausa                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "haw      Hawaiian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "iw       Hebrew                vtt, ttml, srv3, srv2, srv1, json3\n",
      "hi       Hindi                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "hmn      Hmong                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "hu       Hungarian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "is       Icelandic             vtt, ttml, srv3, srv2, srv1, json3\n",
      "ig       Igbo                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "id       Indonesian            vtt, ttml, srv3, srv2, srv1, json3\n",
      "ga       Irish                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "it       Italian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ja       Japanese              vtt, ttml, srv3, srv2, srv1, json3\n",
      "jv       Javanese              vtt, ttml, srv3, srv2, srv1, json3\n",
      "kn       Kannada               vtt, ttml, srv3, srv2, srv1, json3\n",
      "kk       Kazakh                vtt, ttml, srv3, srv2, srv1, json3\n",
      "km       Khmer                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "rw       Kinyarwanda           vtt, ttml, srv3, srv2, srv1, json3\n",
      "ko       Korean                vtt, ttml, srv3, srv2, srv1, json3\n",
      "kri      Krio                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "ku       Kurdish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ky       Kyrgyz                vtt, ttml, srv3, srv2, srv1, json3\n",
      "lo       Lao                   vtt, ttml, srv3, srv2, srv1, json3\n",
      "la       Latin                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "lv       Latvian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ln       Lingala               vtt, ttml, srv3, srv2, srv1, json3\n",
      "lt       Lithuanian            vtt, ttml, srv3, srv2, srv1, json3\n",
      "lb       Luxembourgish         vtt, ttml, srv3, srv2, srv1, json3\n",
      "mk       Macedonian            vtt, ttml, srv3, srv2, srv1, json3\n",
      "mg       Malagasy              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ms       Malay                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "ml       Malayalam             vtt, ttml, srv3, srv2, srv1, json3\n",
      "mt       Maltese               vtt, ttml, srv3, srv2, srv1, json3\n",
      "mi       Māori                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "mr       Marathi               vtt, ttml, srv3, srv2, srv1, json3\n",
      "mn       Mongolian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "ne       Nepali                vtt, ttml, srv3, srv2, srv1, json3\n",
      "nso      Northern Sotho        vtt, ttml, srv3, srv2, srv1, json3\n",
      "no       Norwegian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "ny       Nyanja                vtt, ttml, srv3, srv2, srv1, json3\n",
      "or       Odia                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "om       Oromo                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "ps       Pashto                vtt, ttml, srv3, srv2, srv1, json3\n",
      "fa       Persian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "pl       Polish                vtt, ttml, srv3, srv2, srv1, json3\n",
      "pt       Portuguese            vtt, ttml, srv3, srv2, srv1, json3\n",
      "pa       Punjabi               vtt, ttml, srv3, srv2, srv1, json3\n",
      "qu       Quechua               vtt, ttml, srv3, srv2, srv1, json3\n",
      "ro       Romanian              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ru       Russian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "sm       Samoan                vtt, ttml, srv3, srv2, srv1, json3\n",
      "sa       Sanskrit              vtt, ttml, srv3, srv2, srv1, json3\n",
      "gd       Scottish Gaelic       vtt, ttml, srv3, srv2, srv1, json3\n",
      "sr       Serbian               vtt, ttml, srv3, srv2, srv1, json3\n",
      "sn       Shona                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "sd       Sindhi                vtt, ttml, srv3, srv2, srv1, json3\n",
      "si       Sinhala               vtt, ttml, srv3, srv2, srv1, json3\n",
      "sk       Slovak                vtt, ttml, srv3, srv2, srv1, json3\n",
      "sl       Slovenian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "so       Somali                vtt, ttml, srv3, srv2, srv1, json3\n",
      "st       Southern Sotho        vtt, ttml, srv3, srv2, srv1, json3\n",
      "es       Spanish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "su       Sundanese             vtt, ttml, srv3, srv2, srv1, json3\n",
      "sw       Swahili               vtt, ttml, srv3, srv2, srv1, json3\n",
      "sv       Swedish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "tg       Tajik                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "ta       Tamil                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "tt       Tatar                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "te       Telugu                vtt, ttml, srv3, srv2, srv1, json3\n",
      "th       Thai                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "ti       Tigrinya              vtt, ttml, srv3, srv2, srv1, json3\n",
      "ts       Tsonga                vtt, ttml, srv3, srv2, srv1, json3\n",
      "tr       Turkish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "tk       Turkmen               vtt, ttml, srv3, srv2, srv1, json3\n",
      "uk       Ukrainian             vtt, ttml, srv3, srv2, srv1, json3\n",
      "ur       Urdu                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "ug       Uyghur                vtt, ttml, srv3, srv2, srv1, json3\n",
      "uz       Uzbek                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "vi       Vietnamese            vtt, ttml, srv3, srv2, srv1, json3\n",
      "cy       Welsh                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "fy       Western Frisian       vtt, ttml, srv3, srv2, srv1, json3\n",
      "xh       Xhosa                 vtt, ttml, srv3, srv2, srv1, json3\n",
      "yi       Yiddish               vtt, ttml, srv3, srv2, srv1, json3\n",
      "yo       Yoruba                vtt, ttml, srv3, srv2, srv1, json3\n",
      "zu       Zulu                  vtt, ttml, srv3, srv2, srv1, json3\n",
      "bpu2hbpQpCY has no subtitles\n",
      "dict_keys(['af', 'ak', 'sq', 'am', 'ar-orig', 'ar', 'hy', 'as', 'ay', 'az', 'bn', 'eu', 'be', 'bho', 'bs', 'bg', 'my', 'ca', 'ceb', 'zh-Hans', 'zh-Hant', 'co', 'hr', 'cs', 'da', 'dv', 'nl', 'en', 'eo', 'et', 'ee', 'fil', 'fi', 'fr', 'gl', 'lg', 'ka', 'de', 'el', 'gn', 'gu', 'ht', 'ha', 'haw', 'iw', 'hi', 'hmn', 'hu', 'is', 'ig', 'id', 'ga', 'it', 'ja', 'jv', 'kn', 'kk', 'km', 'rw', 'ko', 'kri', 'ku', 'ky', 'lo', 'la', 'lv', 'ln', 'lt', 'lb', 'mk', 'mg', 'ms', 'ml', 'mt', 'mi', 'mr', 'mn', 'ne', 'nso', 'no', 'ny', 'or', 'om', 'ps', 'fa', 'pl', 'pt', 'pa', 'qu', 'ro', 'ru', 'sm', 'sa', 'gd', 'sr', 'sn', 'sd', 'si', 'sk', 'sl', 'so', 'st', 'es', 'su', 'sw', 'sv', 'tg', 'ta', 'tt', 'te', 'th', 'ti', 'ts', 'tr', 'tk', 'uk', 'ur', 'ug', 'uz', 'vi', 'cy', 'fy', 'xh', 'yi', 'yo', 'zu'])\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def check_arabic_auto_subtitles(video_url):\n",
    "    ydl_opts = {\n",
    "        'listsubtitles': True,\n",
    "        'skip_download': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(video_url, download=False)\n",
    "        subtitles = result.get('subtitles', {})\n",
    "        auto_subtitles = result.get('automatic_captions', {})\n",
    "    \n",
    "        print(auto_subtitles.keys())\n",
    "# video_url = \"https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\"\n",
    "\n",
    "video_url = \"https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\"\n",
    "check_arabic_auto_subtitles(video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = YouTube(r\"https://www.youtube.com/watch?v=bpu2hbpQpCY&pp=ygUM2KfZhNij2LHYr9mG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView({})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = YouTube(r\"https://www.youtube.com/watch?v=lPrjP4A_X4s\")\n",
    "# stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "\n",
    "\"a.ar\" in yt.captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
