{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Code-Projects\\\\University\\\\Fall2023\\\\Grad\\\\LipNet-Assistive-AI\\\\.conda\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = r\"E:/Video Links Dataset\"\n",
    "CLIPPED_VIDEOS = WORK_DIR + r\"/clipped/videos\"\n",
    "CLIPPED_ALIGNMENTS = WORK_DIR + r\"/clipped/alignments\"\n",
    "DOWNLOADED_VIDEOS = WORK_DIR + r\"/downloaded/videos\"\n",
    "DOWNLOADED_ALIGNMENTS = WORK_DIR + r\"/downloaded/alignments\"\n",
    "FILTERED_VIDEOS = WORK_DIR + r\"/filtered/videos\"\n",
    "FILTERED_ALIGNMENTS = WORK_DIR + r\"/filtered/alignments\"\n",
    "LINK_DATASET = WORK_DIR + r\"/Video Links Dataset.csv\"\n",
    "STATUS_DATASET = WORK_DIR + r\"/Video Status.csv\"\n",
    "LOG_FILE = WORK_DIR + r\"/log.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx.all import crop\n",
    "from os import path, remove, makedirs, rename\n",
    "from cv2 import VideoCapture,cvtColor, absdiff,COLOR_BGR2RGB,COLOR_BGR2GRAY,CAP_PROP_FPS,CAP_PROP_FRAME_COUNT\n",
    "from mediapipe.python.solutions.face_mesh import FaceMesh\n",
    "from mediapipe.python.solutions.face_detection import FaceDetection\n",
    "from pandas import read_csv, concat,DataFrame\n",
    "from numpy import mean\n",
    "from time import sleep\n",
    "import pysrt\n",
    "import re \n",
    "from string import punctuation\n",
    "from subprocess import run\n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from matplotlib.pyplot import plot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def cut_from_srt_file(video_path, srt_path, output_dir_videos,output_dir_str, id):\n",
    "    \n",
    "#     subs = pysrt.open(srt_path)\n",
    "#     video = VideoFileClip(video_path)\n",
    "\n",
    "#     makedir(output_dir_videos, exist_ok=True)\n",
    "\n",
    "#     for idx, sub in enumerate(subs):\n",
    "#         try:\n",
    "#             text = filter_srt_sub(sub.text.strip())\n",
    "\n",
    "#             if( not text):\n",
    "#                 continue\n",
    "\n",
    "#             start_time = sub.start.ordinal /1000.0\n",
    "#             end_time = sub.end.ordinal / 1000.0     \n",
    "\n",
    "#             video_part = video.subclip(start_time, end_time)\n",
    "#             output_path = path.join(output_dir_videos, f\"{id}_{idx+1}.mp4\")\n",
    "            \n",
    "#             with open(output_dir_str+f\"/{id}_{idx+1}.align\",\"w\") as writer:\n",
    "#                 writer.write(text.replace(\" \",\"\\n\"))\n",
    "\n",
    "#             video_part.write_videofile(output_path,verbose=False, progress_bar=False) \n",
    "#         except:\n",
    "#             video.close()\n",
    "#             pass\n",
    "#     video.close()\n",
    "\n",
    "\n",
    "\n",
    "# def filter_videos(videos_path,alignments_path):\n",
    "#     for i in glob(videos_path+fr\"/*.mp4\"):\n",
    "#         video_path = i.replace(\"\\\\\",\"/\")\n",
    "#         alignment_path = alignments_path+\"/\"+re.split(r\"\\\\|/\",i)[-1].split(\".\")[0]+\".align\"\n",
    "\n",
    "#         if(video_is_accpeted(video_path)):\n",
    "#             copy(video_path, FILTERED_VIDEOS)\n",
    "#             copy(alignment_path, FILTERED_ALIGNMENTS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(numbers,threshold):\n",
    "    if not numbers:\n",
    "        return False  # Return False if the list is empty\n",
    "\n",
    "    mean = sum(numbers) / len(numbers)\n",
    "    \n",
    "    # Calculate standard deviation\n",
    "    variance = sum((x - mean) ** 2 for x in numbers) / len(numbers)\n",
    "    std_dev = variance ** 0.5\n",
    "    \n",
    "    # Define thresholds\n",
    "    upper_threshold = mean + (threshold * std_dev)\n",
    "    \n",
    "    # Check if any number falls outside the thresholds\n",
    "    for num in numbers:\n",
    "        if num > upper_threshold:\n",
    "            return True  # Return True if any number is outside the thresholds\n",
    "    \n",
    "    return False  # Return False if no number is outside the thresholds\n",
    "\n",
    "def calculate_frame_differences(video_path):\n",
    "    cap = VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        # print(\"Error: Couldn't open video file.\")\n",
    "        return None\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        # print(\"Error: Couldn't read the first frame.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize list to store differences\n",
    "    differences = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Calculate absolute difference between frames\n",
    "        diff = absdiff(prev_frame, frame)\n",
    "        \n",
    "        # Convert difference image to grayscale\n",
    "        gray_diff = cvtColor(diff, COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate the average pixel difference\n",
    "        avg_diff = mean(gray_diff)\n",
    "        differences.append(avg_diff)\n",
    "        \n",
    "        # Update the previous frame\n",
    "        prev_frame = frame.copy()\n",
    "    cap.release()\n",
    "    # plt.plot(differences);\n",
    "    return(check_outliers(differences,4))\n",
    "\n",
    "def english_to_arabic_numbers(text):\n",
    "\n",
    "    numbers_dict = {\n",
    "        '0': '٠',\n",
    "        '1': '١',\n",
    "        '2': '٢',\n",
    "        '3': '٣',\n",
    "        '4': '٤',\n",
    "        '5': '٥',\n",
    "        '6': '٦',\n",
    "        '7': '٧',\n",
    "        '8': '٨',\n",
    "        '9': '٩',\n",
    "    }\n",
    "    for eng_num, arabic_num in numbers_dict.items():\n",
    "        text = text.replace(eng_num, arabic_num)\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    for i in punctuation:\n",
    "        text = text.replace(i, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_repeating_spaces(text):\n",
    "    cleaned_text = re.sub(r' +', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def check_if_not_arabic(text):\n",
    "    ar = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويىء٠١٢٣٤٥٦٧٨٩ \"\n",
    "    for i in text:\n",
    "        if i not in ar:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_video(url, video_id):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "\n",
    "        if \"a.ar\" in yt.captions.keys():\n",
    "            captions = yt.captions.get_by_language_code(\"a.ar\")\n",
    "            captions.download(\n",
    "                srt=True,\n",
    "                output_path=DOWNLOADED_ALIGNMENTS,\n",
    "                title=f\"{video_id}\")\n",
    "\n",
    "            stream.download(\n",
    "                filename=fr\"{DOWNLOADED_VIDEOS}/{video_id}.mp4\"\n",
    "            )\n",
    "\n",
    "            return fr\"{DOWNLOADED_VIDEOS}/{video_id}.mp4\",fr\"{DOWNLOADED_ALIGNMENTS}/{video_id} (a.ar).srt\"\n",
    "\n",
    "        else:\n",
    "            return False, False\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None,None\n",
    "    \n",
    "def video_is_accpeted(video_path):\n",
    "\n",
    "    try:\n",
    "        # open video file\n",
    "        cap = VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(\"can't open video file\")\n",
    "        \n",
    "        # setup models\n",
    "        face_mesh = FaceMesh(min_detection_confidence=0.8)\n",
    "        face_detection = FaceDetection(model_selection=2, min_detection_confidence=0.8)\n",
    "\n",
    "        video_fps = int(cap.get(CAP_PROP_FPS))\n",
    "        video_frames = int(cap.get(CAP_PROP_FRAME_COUNT))\n",
    "        video_duration = video_frames // video_fps\n",
    "\n",
    "        if (int(video_duration) < 2) or (int(video_duration) > 5):\n",
    "            raise Exception(\"video_duration must be between 2 and 5\")\n",
    "        \n",
    "        if((video_fps < 25) or (video_fps > 60)):\n",
    "            raise Exception(\"video fps must be between 25 and 60\")\n",
    "\n",
    "        # lip coordinates,\n",
    "        lip_pairs = [[13, 14], [82, 87], [312, 317],[81,178],[311,402],[310,318],[80,88]]\n",
    "        # list for whether face is facing us\n",
    "        orientation_list=[]\n",
    "        # list for whether frames are lips are moving rapidly\n",
    "        lip_diffs = []\n",
    "\n",
    "        # loop over all frames in the video\n",
    "        for _ in range(int(cap.get(CAP_PROP_FRAME_COUNT))):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                raise Exception(\"couldn't read frame\")\n",
    "            \n",
    "            # convert to rgb\n",
    "            frame = cvtColor(frame, COLOR_BGR2RGB)\n",
    "\n",
    "            # get the keypoints (x,y)s of each point of a face in the frame\n",
    "            results = face_detection.process(frame)\n",
    "\n",
    "            if not results.detections:\n",
    "                raise Exception(\"no faces detected\")\n",
    "            \n",
    "            if(len(results.detections) !=1):\n",
    "                raise Exception(\"wrong number of faces detected\")\n",
    "\n",
    "\n",
    "            face_mesh_result = face_mesh.process(frame)\n",
    "            if not face_mesh_result.multi_face_landmarks:\n",
    "                raise Exception(\"no lips detected\")\n",
    "            \n",
    "            for face_landmarks in face_mesh_result.multi_face_landmarks:\n",
    "\n",
    "                landmarks = face_landmarks.landmark\n",
    "                right_x = int(landmarks[454].x * frame.shape[1])\n",
    "                left_x = int(landmarks[234].x * frame.shape[1])\n",
    "                upper_x = int(landmarks[10].x * frame.shape[1])\n",
    "                lower_x = int(landmarks[152].x * frame.shape[1])\n",
    "\n",
    "                center_x = (upper_x + lower_x)//2\n",
    "\n",
    "                if(left_x>center_x):\n",
    "                    orientation_list.append(0)\n",
    "                elif(right_x<center_x):\n",
    "                    orientation_list.append(0)\n",
    "                else:\n",
    "                    orientation_list.append(1)\n",
    "                    \n",
    "                diff = 0\n",
    "                for lip_pair in lip_pairs:\n",
    "                    upper_lip_x, upper_lip_y = int(\n",
    "                        landmarks[lip_pair[0]].x * frame.shape[1]\n",
    "                    ), int(landmarks[lip_pair[0]].y * frame.shape[0])\n",
    "                    lower_lip_x, lower_lip_y = int(\n",
    "                        landmarks[lip_pair[1]].x * frame.shape[1]\n",
    "                    ), int(landmarks[lip_pair[1]].y * frame.shape[0])\n",
    "                    diff += ((upper_lip_x - lower_lip_x) ** 2) + (\n",
    "                        (upper_lip_y - lower_lip_y) ** 2\n",
    "                    )\n",
    "                lip_diffs.append(diff)\n",
    "            \n",
    "        if(len(orientation_list) == 0):\n",
    "            raise Exception(\"Face border coudn't detect any face for orientation\")\n",
    "        if(len(lip_diffs) == 0 ):\n",
    "            raise Exception(\"Face mesh couldn't detect any lips\")\n",
    "        \n",
    "        if((sum(orientation_list)/len(orientation_list)) !=1.0):\n",
    "            raise Exception(\"too much face angle\")\n",
    "\n",
    "        if(not check_outliers(lip_diffs,1)):\n",
    "            raise Exception(\"lips not moving\")\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "        if calculate_frame_differences(video_path):\n",
    "            raise Exception(\"sudden change in frames\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "\n",
    "### logging and control functions ###\n",
    "\n",
    "def empty_dir(dir):\n",
    "    for i in glob(dir+r\"/*\"):\n",
    "        remove(i)\n",
    "        \n",
    "def log(text):\n",
    "    try:\n",
    "        with open(LOG_FILE, 'a') as file:\n",
    "            file.write(text)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to log: \",text, e)\n",
    "def save_pipeline_status(video_idx,status):\n",
    "    df = read_csv(LINK_DATASET)\n",
    "    df[\"status\"][video_idx] = status\n",
    "    df.to_csv(LINK_DATASET,index=False)    \n",
    "\n",
    "def log_status_video(video_id, status):\n",
    "    status_df = read_csv(STATUS_DATASET)\n",
    "    new_row = {'video_id': video_id, 'status': status}\n",
    "    status_df = concat([status_df, DataFrame([new_row])], ignore_index=True)\n",
    "    status_df.to_csv(STATUS_DATASET,index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(url,video_id):\n",
    "    log(f\"Downloading video: {video_id}\\n\\n\")\n",
    "\n",
    "    try:\n",
    "                \n",
    "        fails = 10\n",
    "\n",
    "        output_video, output_alignment = get_video(url,video_id)\n",
    "        while (output_video == None) and (fails > 0):\n",
    "            fails -= 1\n",
    "            sleep(4)\n",
    "            output_video, output_alignment = download_video(url,video_id)\n",
    "\n",
    "        if not output_video:\n",
    "            raise Exception(f\"Video not downloading after {fails} times\")\n",
    "\n",
    "        # fix srt file\n",
    "        run([\"go\",\"run\",\".\",output_alignment])\n",
    "        remove(fr\"{DOWNLOADED_ALIGNMENTS}/{video_id} (a.ar).srt\")\n",
    "        rename(fr\"{DOWNLOADED_ALIGNMENTS}/{video_id} (a.ar).srt.fixed\",fr\"{DOWNLOADED_ALIGNMENTS}/{video_id}.srt\")\n",
    "        log(f\"Finished Downloading video: {video_id}\\n\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "     \n",
    "def clip_video(video_path, alignment_path,video_id):\n",
    "    log(f\"Clipping videos: {video_path}\\n\\n\")\n",
    "\n",
    "    def filter_srt_sub(text):\n",
    "    \n",
    "        if(len(text) < 2):\n",
    "            return False\n",
    "\n",
    "        if(text == \"[موسيقى]\"):\n",
    "            return False\n",
    "        \n",
    "        text = english_to_arabic_numbers(text)\n",
    "        text = remove_special_char(text)\n",
    "        text = remove_repeating_spaces(text)\n",
    "        \n",
    "        if(check_if_not_arabic(text)):\n",
    "            return False\n",
    "        \n",
    "        if(len(text) < 2):\n",
    "            return False\n",
    "        \n",
    "        return text\n",
    "    try:\n",
    "        subs = pysrt.open(alignment_path)\n",
    "        video = VideoFileClip(video_path)\n",
    "\n",
    "        for idx, sub in enumerate(subs):\n",
    "            try:\n",
    "                text = filter_srt_sub(sub.text.strip())\n",
    "\n",
    "                if(not text):\n",
    "                    continue\n",
    "\n",
    "                start_time = sub.start.ordinal /1000.0\n",
    "                end_time = sub.end.ordinal / 1000.0     \n",
    "\n",
    "                video_part = video.subclip(start_time, end_time)\n",
    "                output_path = path.join(CLIPPED_VIDEOS, f\"{video_id}_{idx+1}.mp4\")\n",
    "                \n",
    "                with open(CLIPPED_ALIGNMENTS+f\"/{video_id}_{idx+1}.align\",\"w\") as writer:\n",
    "                    writer.write(text.replace(\" \",\"\\n\"))\n",
    "\n",
    "                video_part.write_videofile(output_path,verbose=False, progress_bar=False) \n",
    "            except:\n",
    "                video.close()\n",
    "        video.close()\n",
    "        log(f\"Finished Clipping videos: {video_path}\\n\\n\")\n",
    "\n",
    "    except:\n",
    "        raise Exception(\"Failed to open srt file or video file\")\n",
    "\n",
    "def filter_video():\n",
    "    log(\"Filtering Videos\\n\\n\")\n",
    "    try:\n",
    "        for i in glob(CLIPPED_VIDEOS+fr\"/*.mp4\"):\n",
    "            video_id = re.split(r\"\\\\|/\",i)[-1].split(\".\")[0]\n",
    "            video_path = i.replace(\"\\\\\",\"/\")\n",
    "            alignment_path = CLIPPED_ALIGNMENTS+\"/\"+video_id+\".align\"\n",
    "\n",
    "\n",
    "            try:\n",
    "                video_is_accpeted(video_path)\n",
    "                copy(video_path,FILTERED_VIDEOS)\n",
    "                copy(alignment_path,FILTERED_ALIGNMENTS)\n",
    "                log_status_video(video_id,\"parsed\")\n",
    "            except Exception as e:\n",
    "                log_status_video(video_id,e)\n",
    "        log(\"\\nFinished Filtering Videos\\n\\n\")\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline(url, video_id,status,video_idx):\n",
    "    log(f\"{'='*100}\\n\\n\")\n",
    "    log(f\"Start Pipline for id: {video_id} with status: {status}\\n\\n\")\n",
    "    try:\n",
    "        if status == \"parsed\":\n",
    "            log(f\"Finished Pipline for id: {video_id}\\n\\n\")\n",
    "            log(f\"{'='*100}\\n\\n\")\n",
    "            return \"parsed\"\n",
    "        \n",
    "        elif status == \"downloaded\":\n",
    "            empty_dir(CLIPPED_VIDEOS)\n",
    "            empty_dir(CLIPPED_ALIGNMENTS)\n",
    "\n",
    "            clip_video(DOWNLOADED_VIDEOS+fr\"/{video_id}.mp4\", DOWNLOADED_ALIGNMENTS+fr\"/{video_id}.srt\",video_id)\n",
    "            save_pipeline_status(video_idx,\"clipped\")\n",
    "\n",
    "            filter_video()\n",
    "            empty_dir(CLIPPED_VIDEOS)\n",
    "            empty_dir(CLIPPED_ALIGNMENTS)\n",
    "            empty_dir(DOWNLOADED_VIDEOS)\n",
    "            empty_dir(DOWNLOADED_ALIGNMENTS)\n",
    "            log(f\"Finished Pipline for id: {video_id}\\n\\n\")\n",
    "            log(f\"{'='*100}\\n\\n\")\n",
    "            return \"parsed\"\n",
    "\n",
    "        elif status == \"clipped\":\n",
    "            filter_video()\n",
    "            empty_dir(CLIPPED_VIDEOS)\n",
    "            empty_dir(CLIPPED_ALIGNMENTS)\n",
    "            empty_dir(DOWNLOADED_VIDEOS)\n",
    "            empty_dir(DOWNLOADED_ALIGNMENTS)\n",
    "            log(f\"Finished Pipline for id: {video_id}\\n\\n\")\n",
    "            log(f\"{'='*100}\\n\\n\")\n",
    "            return \"parsed\"\n",
    "\n",
    "            \n",
    "        elif status == \"failed\" or status == \"unparsed\":\n",
    "            empty_dir(CLIPPED_VIDEOS)\n",
    "            empty_dir(CLIPPED_ALIGNMENTS)\n",
    "            empty_dir(DOWNLOADED_VIDEOS)\n",
    "            empty_dir(DOWNLOADED_ALIGNMENTS)\n",
    "\n",
    "            download_video(url,video_id)\n",
    "            save_pipeline_status(video_idx,\"downloaded\")\n",
    "\n",
    "            clip_video(DOWNLOADED_VIDEOS+fr\"/{video_id}.mp4\", DOWNLOADED_ALIGNMENTS+fr\"/{video_id}.srt\",video_id)\n",
    "            save_pipeline_status(video_idx,\"clipped\")\n",
    "\n",
    "            filter_video()\n",
    "\n",
    "            empty_dir(CLIPPED_VIDEOS)\n",
    "            empty_dir(CLIPPED_ALIGNMENTS)\n",
    "            empty_dir(DOWNLOADED_VIDEOS)\n",
    "            empty_dir(DOWNLOADED_ALIGNMENTS)\n",
    "            log(f\"Finished Pipline for id: {video_id}\\n\\n\")\n",
    "            log(f\"{'='*100}\\n\\n\")\n",
    "            return \"parsed\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"ERROR Pipeline for {video_id}:\\n\\n\")\n",
    "        log(f\"Finished Pipline for id: {video_id}\\n\\n\")\n",
    "        log(f\"{'='*100}\\n\\n\")\n",
    "        log(f\"{e}\\n\\n\")\n",
    "        empty_dir(CLIPPED_VIDEOS)\n",
    "        empty_dir(CLIPPED_ALIGNMENTS)\n",
    "        empty_dir(DOWNLOADED_VIDEOS)\n",
    "        empty_dir(DOWNLOADED_ALIGNMENTS)\n",
    "        return e    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=s0pbzSC81Kc</td>\n",
       "      <td>كتابة الكلام على الفيديو بشكل تلقائي بالذكاء ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unparsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=FYqNG3zwXL4&amp;t=...</td>\n",
       "      <td>فيلم الصفاره</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unparsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=3r3IOzNNKRM</td>\n",
       "      <td>جت كدا اياد الموجي وساره هاني</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>unparsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=Z31F0zVuHOg&amp;t=...</td>\n",
       "      <td>فيلم العارف</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>unparsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=0SGpG7m4xzE</td>\n",
       "      <td>فيلم الخليه</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>unparsed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0        https://www.youtube.com/watch?v=s0pbzSC81Kc   \n",
       "1  https://www.youtube.com/watch?v=FYqNG3zwXL4&t=...   \n",
       "2        https://www.youtube.com/watch?v=3r3IOzNNKRM   \n",
       "3  https://www.youtube.com/watch?v=Z31F0zVuHOg&t=...   \n",
       "4        https://www.youtube.com/watch?v=0SGpG7m4xzE   \n",
       "\n",
       "                                                name  id  creator    status  \n",
       "0  كتابة الكلام على الفيديو بشكل تلقائي بالذكاء ا...   0        0  unparsed  \n",
       "1                                       فيلم الصفاره   1        0  unparsed  \n",
       "2                      جت كدا اياد الموجي وساره هاني   2        0  unparsed  \n",
       "3                                        فيلم العارف   3        0  unparsed  \n",
       "4                                        فيلم الخليه   4        0  unparsed  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(LINK_DATASET)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [link, name, id, creator, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated('link',keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in enumerate(df.values):\n",
    "    url = row[0]\n",
    "    video_id = row[2]\n",
    "    status = row[4]\n",
    "    break\n",
    "    # run pipline\n",
    "    result = pipline(url, video_id,status,idx)\n",
    "    # # save completion\n",
    "    save_pipeline_status(idx,result)\n",
    "    # df[\"status\"][idx] = result\n",
    "    # df.to_csv(LINK_DATASET,index=False)    \n",
    "    print(\"Parsed Video : \",video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipline(url, video_id,status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in captions.py\n",
    "    # def xml_caption_to_srt(self, xml_captions: str) -> str:\n",
    "    #     \"\"\"Convert xml caption tracks to \"SubRip Subtitle (srt)\".\n",
    "\n",
    "    #     :param str xml_captions:\n",
    "    #     XML formatted caption tracks.\n",
    "    #     \"\"\"\n",
    "    #     segments = []\n",
    "    #     root = ElementTree.fromstring(xml_captions)\n",
    "    #     i=0\n",
    "    #     for child in list(root.iter(\"body\"))[0]:\n",
    "    #         if child.tag == 'p':\n",
    "    #             caption = ''\n",
    "    #             if len(list(child))==0:\n",
    "    #                 # instead of 'continue'\n",
    "    #                 caption = child.text\n",
    "    #             for s in list(child):\n",
    "    #                 if s.tag == 's':\n",
    "    #                     caption += ' ' + s.text\n",
    "    #             caption = unescape(caption.replace(\"\\n\", \" \").replace(\"  \", \" \"),)\n",
    "    #             try:\n",
    "    #                 duration = float(child.attrib[\"d\"])/1000.0\n",
    "    #             except KeyError:\n",
    "    #                 duration = 0.0\n",
    "    #             start = float(child.attrib[\"t\"])/1000.0\n",
    "    #             end = start + duration\n",
    "    #             sequence_number = i + 1  # convert from 0-indexed to 1.\n",
    "    #             line = \"{seq}\\n{start} --> {end}\\n{text}\\n\".format(\n",
    "    #                 seq=sequence_number,\n",
    "    #                 start=self.float_to_srt_time_format(start),\n",
    "    #                 end=self.float_to_srt_time_format(end),\n",
    "    #                 text=caption,\n",
    "    #             )\n",
    "    #             segments.append(line)\n",
    "    #             i += 1\n",
    "    #     return \"\\n\".join(segments).strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
