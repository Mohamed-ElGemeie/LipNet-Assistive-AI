{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Code-Projects\\\\University\\\\Fall2023\\\\Grad\\\\LipNet-Assistive-AI\\\\.conda\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx.all import crop\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import pysrt\n",
    "import re\n",
    "import string\n",
    "import subprocess\n",
    "import glob\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download video\n",
    "def download_video(url, id):\n",
    "        try:\n",
    "            yt = YouTube(url)\n",
    "\n",
    "            stream = (\n",
    "                yt.streams.filter(progressive=True, file_extension=\"mp4\").get_highest_resolution()\n",
    "            )\n",
    "\n",
    "            if \"a.ar\" in yt.captions.keys():\n",
    "                captions = yt.captions.get_by_language_code(\"a.ar\")\n",
    "                captions.download(\n",
    "                    srt=True,\n",
    "                    output_path=r\"data/Video Links Dataset/temp_alignments\",\n",
    "                    title=f\"{id}\")\n",
    "\n",
    "                stream.download(\n",
    "                    filename=fr\"data/Video Links Dataset/temp_videos/{id}.mp4\"\n",
    "                )\n",
    "\n",
    "                return fr\"data/Video Links Dataset/temp_videos/{id}.mp4\",fr\"data/Video Links Dataset/temp_alignments/{id} (a.ar).srt\", id\n",
    "\n",
    "            else:\n",
    "                print(\"skipping video no arabic subtitles\")\n",
    "                return False, False, False\n",
    "            \n",
    "        except Exception as e:\n",
    "             print(e)\n",
    "             return None,None, None\n",
    "\n",
    "\n",
    "# # Function to cut video into generated video segments\n",
    "# def cut_video_into_segments(video_path, segment_length=2):\n",
    "\n",
    "#     # cut the segments into similary named parts as the parent\n",
    "\n",
    "#     clip = VideoFileClip(video_path)\n",
    "#     duration = int(clip.duration)\n",
    "#     for start in range(0, duration, segment_length):\n",
    "#         end = min(start + segment_length, duration)\n",
    "#         segment = clip.subclip(start, end)\n",
    "#         segment_filename = f\"output_segment_{start}_{end}.mp4\"\n",
    "#         segment.write_videofile(segment_filename, codec=\"libx264\", audio_codec=\"aac\")\n",
    "        \n",
    "def english_to_arabic_numbers(text):\n",
    "\n",
    "    numbers_dict = {\n",
    "        '0': '٠',\n",
    "        '1': '١',\n",
    "        '2': '٢',\n",
    "        '3': '٣',\n",
    "        '4': '٤',\n",
    "        '5': '٥',\n",
    "        '6': '٦',\n",
    "        '7': '٧',\n",
    "        '8': '٨',\n",
    "        '9': '٩',\n",
    "    }\n",
    "    for eng_num, arabic_num in numbers_dict.items():\n",
    "        text = text.replace(eng_num, arabic_num)\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_repeating_spaces(text):\n",
    "    cleaned_text = re.sub(r' +', ' ', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def check_if_not_arabic(text):\n",
    "    ar = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويىء٠١٢٣٤٥٦٧٨٩ \"\n",
    "    for i in text:\n",
    "        if i not in ar:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_srt_sub(text):\n",
    "    \n",
    "    if(len(text) < 2):\n",
    "        return False\n",
    "\n",
    "    if(text == \"[موسيقى]\"):\n",
    "        return False\n",
    "    \n",
    "    text = english_to_arabic_numbers(text)\n",
    "    text = remove_special_char(text)\n",
    "    text = remove_repeating_spaces(text)\n",
    "    \n",
    "    if(check_if_not_arabic(text)):\n",
    "        return False\n",
    "    \n",
    "    if(len(text) < 2):\n",
    "        return False\n",
    "    \n",
    "    return text\n",
    "\n",
    "def filter_lip_segment():\n",
    "    pass\n",
    "\n",
    "def cut_from_srt_file(video_path, srt_path, output_dir_videos,output_dir_str, id):\n",
    "    \n",
    "    subs = pysrt.open(srt_path)\n",
    "    video = VideoFileClip(video_path)\n",
    "\n",
    "    os.makedirs(output_dir_videos, exist_ok=True)\n",
    "\n",
    "    for idx, sub in enumerate(subs):\n",
    "        text = filter_srt_sub(sub.text.strip())\n",
    "\n",
    "        if( not text):\n",
    "            continue\n",
    "\n",
    "        start_time = sub.start.ordinal /1000.0\n",
    "        end_time = sub.end.ordinal / 1000     \n",
    "\n",
    "        video_part = video.subclip(start_time, end_time)\n",
    "        output_path = os.path.join(output_dir_videos, f\"{id}_{idx+1}.mp4\")\n",
    "        \n",
    "        with open(output_dir_str+f\"/{id}_{idx+1}.align\",\"w\") as writer:\n",
    "            writer.write(text.replace(\" \",\"\\n\"))\n",
    "\n",
    "        video_part.write_videofile(output_path)\n",
    "\n",
    "\n",
    "    video.close()\n",
    "\n",
    "def video_is_accpeted(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) > 300):\n",
    "        return False\n",
    "    \n",
    "    # frames of the video\n",
    "    # frames = np.empty((max_frames, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "# discard when\n",
    "# orentation of face not in camera range  for 0.8 of frames \n",
    "\n",
    "# cut when\n",
    "# start for massive deviation of lips movment, end when end of deviation\n",
    "    # idx = 0\n",
    "    bad_face = False\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=2, min_detection_confidence=1\n",
    "    ) as face_detection:\n",
    "        # loop over all frames in the video\n",
    "        for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # convert to rgb\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # get the keypoints (x,y)s of each point of a face in the frame\n",
    "            results = face_detection.process(frame)\n",
    "            if results.detections:\n",
    "                if(len(results.detections) !=1):\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "            # check orientation\n",
    "\n",
    "\n",
    "\n",
    "            # check if lips closed\n",
    "\n",
    "\n",
    "            # loop over each face landmark ~ (nose (x,y) lips (x,y) and so one and a bounding box)\n",
    "            # if results.detections:\n",
    "            #     for detection in results.detections:\n",
    "            #         location = detection.location_data\n",
    "\n",
    "\n",
    "    return True\n",
    "    pass\n",
    "\n",
    "def filter_videos(videos_path,alignments_path,output_videos,output_alignments,id):\n",
    "    for i in glob.glob(videos_path+fr\"/{id}*.mp4\"):\n",
    "        video_path = i.replace(\"\\\\\",\"/\")\n",
    "        alignment_path = alignments_path+\"/\"+re.split(r\"\\\\|/\",i)[-1].split(\".\")[0]+\".align\"\n",
    "        output_video_path = output_videos+\"/\"+re.split(r\"\\\\|/\",i)[-1]\n",
    "        output_alignment_path = output_alignments+\"/\"+re.split(r\"\\\\|/\",i)[-1].split(\".\")[0]+\".align\"\n",
    "\n",
    "        if(video_is_accpeted(video_path)):\n",
    "            shutil.copy(video_path, output_video_path)\n",
    "            shutil.copy(alignment_path, output_alignment_path)\n",
    "            \n",
    "\n",
    "# Function to filter unacceptable video segments\n",
    "\n",
    "# create segments\n",
    "# for loop on all the segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mgala\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Face and Pose modules\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Initialize the MediaPipe drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)  # Use the desired camera index (e.g., 0 for the default camera)\n",
    "\n",
    "# Initialize Face Detection and Pose Estimation models\n",
    "face_detection = mp_face.FaceDetection(min_detection_confidence=0.5)\n",
    "pose_estimation = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    # Convert the frame to RGB format for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform face detection\n",
    "    face_results = face_detection.process(frame_rgb)\n",
    "\n",
    "    if face_results.detections:\n",
    "        for detection in face_results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Perform pose estimation using the face region\n",
    "            face_center = (x + w // 2, y + h // 2)\n",
    "            frame_pose = frame[y:y + h, x:x + w]\n",
    "            frame_pose_rgb = cv2.cvtColor(frame_pose, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Perform pose estimation on the face region\n",
    "            pose_results = pose_estimation.process(frame_pose_rgb)\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                # You can access pose landmarks and orientation information here\n",
    "                landmarks = pose_results.pose_landmarks\n",
    "                # Extract relevant pose landmarks and calculate face orientation\n",
    "\n",
    "                # Draw landmarks and orientation lines\n",
    "                mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Face Orientation Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_from_srt_file(r\"data\\Video Links Dataset\\temp_videos\\0.mp4\", r\"data\\Video Links Dataset\\temp_alignments\\0 (a.ar).srt.fixed\", \n",
    "#                   r\"data\\Video Links Dataset\\temp_videos\",r\"data\\Video Links Dataset\\temp_alignments\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_videos(r\"data/Video Links Dataset/temp_videos\", r\"data/Video Links Dataset/temp_alignments\", \n",
    "                  r\"data/Video Links Dataset/videos\",r\"data/Video Links Dataset/alignments\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline(url, name):\n",
    "    fails = 10\n",
    "\n",
    "    video, alignment, id = download_video(url,name)\n",
    "    while (video == None) and (fails > 0):\n",
    "        fails -= 1\n",
    "        sleep(4)\n",
    "        video, alignment, id = download_video(url,name)\n",
    "\n",
    "    if not video:\n",
    "        return False\n",
    "    print(\"=\"*100)\n",
    "    print(alignment)\n",
    "    print(\"=\"*100)\n",
    "    subprocess.run([\"go\",\"run\",\".\",alignment])\n",
    "\n",
    "    cut_from_srt_file(video,alignment+\".fixed\",r\"data/Video Links Dataset/temp_videos\",r\"data/Video Links Dataset/temp_alignments\", id)\n",
    "    os.remove(video)\n",
    "    os.remove(alignment)\n",
    "    filter_videos(r\"data/Video Links Dataset/temp_videos\",r\"data/Video Links Dataset/temp_alignments\",r\"data/Video Links Dataset/videos\",r\"data/Video Links Dataset/alignments\")\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=s0pbzSC81Kc</td>\n",
       "      <td>كتابة الكلام على الفيديو بشكل تلقائي بالذكاء ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=FYqNG3zwXL4&amp;t=...</td>\n",
       "      <td>فيلم الصفاره</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=cAsTfosN79A</td>\n",
       "      <td>فيلم كابتن مصر</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=SJ6_7W2v8ac</td>\n",
       "      <td>فيلم التجربة الدنماركيه</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=3r3IOzNNKRM</td>\n",
       "      <td>جت كدا اياد الموجي وساره هاني</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0        https://www.youtube.com/watch?v=s0pbzSC81Kc   \n",
       "1  https://www.youtube.com/watch?v=FYqNG3zwXL4&t=...   \n",
       "2        https://www.youtube.com/watch?v=cAsTfosN79A   \n",
       "3        https://www.youtube.com/watch?v=SJ6_7W2v8ac   \n",
       "4        https://www.youtube.com/watch?v=3r3IOzNNKRM   \n",
       "\n",
       "                                                name  id  creator  \n",
       "0  كتابة الكلام على الفيديو بشكل تلقائي بالذكاء ا...   0        0  \n",
       "1                                       فيلم الصفاره   1        0  \n",
       "2                                     فيلم كابتن مصر   2        0  \n",
       "3                            فيلم التجربة الدنماركيه   3        0  \n",
       "4                      جت كدا اياد الموجي وساره هاني   4        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\Video Links Dataset\\Video Links Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [link, name, id, creator]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated('link',keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>\n",
      "====================================================================================================\n",
      "data/Video Links Dataset/temp_alignments/0 (a.ar).srt\n",
      "====================================================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SubRipItem' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# downloaded\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# No CC\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Failed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[1;32m----> 9\u001b[0m      result \u001b[38;5;241m=\u001b[39m \u001b[43mpipline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m      results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     11\u001b[0m      \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mpipline\u001b[1;34m(url, name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     15\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,alignment])\n\u001b[1;32m---> 17\u001b[0m \u001b[43mcut_from_srt_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43malignment\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.fixed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Video Links Dataset/temp_videos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Video Links Dataset/temp_alignments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(video)\n\u001b[0;32m     19\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(alignment)\n",
      "Cell \u001b[1;32mIn[4], line 111\u001b[0m, in \u001b[0;36mcut_from_srt_file\u001b[1;34m(video_path, srt_path, output_dir_videos, output_dir_str, id)\u001b[0m\n\u001b[0;32m    108\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir_videos, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sub \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(subs):\n\u001b[1;32m--> 111\u001b[0m     text \u001b[38;5;241m=\u001b[39m filter_srt_sub(\u001b[43msub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m())\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(text):\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SubRipItem' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "status = []\n",
    "\n",
    "# downloaded\n",
    "# No CC\n",
    "# Failed\n",
    "\n",
    "for row in df.values:\n",
    "     \n",
    "     result = pipline(row[0], row[2])\n",
    "     results.append(result)\n",
    "     break\n",
    "df['has_arabic'] = status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code in captions.py\n",
    "    # def xml_caption_to_srt(self, xml_captions: str) -> str:\n",
    "    #     \"\"\"Convert xml caption tracks to \"SubRip Subtitle (srt)\".\n",
    "\n",
    "    #     :param str xml_captions:\n",
    "    #     XML formatted caption tracks.\n",
    "    #     \"\"\"\n",
    "    #     segments = []\n",
    "    #     root = ElementTree.fromstring(xml_captions)\n",
    "    #     i=0\n",
    "    #     for child in list(root.iter(\"body\"))[0]:\n",
    "    #         if child.tag == 'p':\n",
    "    #             caption = ''\n",
    "    #             if len(list(child))==0:\n",
    "    #                 # instead of 'continue'\n",
    "    #                 caption = child.text\n",
    "    #             for s in list(child):\n",
    "    #                 if s.tag == 's':\n",
    "    #                     caption += ' ' + s.text\n",
    "    #             caption = unescape(caption.replace(\"\\n\", \" \").replace(\"  \", \" \"),)\n",
    "    #             try:\n",
    "    #                 duration = float(child.attrib[\"d\"])/1000.0\n",
    "    #             except KeyError:\n",
    "    #                 duration = 0.0\n",
    "    #             start = float(child.attrib[\"t\"])/1000.0\n",
    "    #             end = start + duration\n",
    "    #             sequence_number = i + 1  # convert from 0-indexed to 1.\n",
    "    #             line = \"{seq}\\n{start} --> {end}\\n{text}\\n\".format(\n",
    "    #                 seq=sequence_number,\n",
    "    #                 start=self.float_to_srt_time_format(start),\n",
    "    #                 end=self.float_to_srt_time_format(end),\n",
    "    #                 text=caption,\n",
    "    #             )\n",
    "    #             segments.append(line)\n",
    "    #             i += 1\n",
    "    #     return \"\\n\".join(segments).strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
